{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "name": "",
  "signature": "sha256:b609ee0c52c54731ac5cddb834704c3ceda10a188d16eb02af90a4c92b73eaa4"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Mathematical Principles in Pattern Recognition (2017/2018)\n",
      "$\\newcommand{\\bPhi}{\\mathbf{\\Phi}}$\n",
      "$\\newcommand{\\bb}{\\mathbf{b}}$\n",
      "$\\newcommand{\\bx}{\\mathbf{x}}$\n",
      "$\\newcommand{\\bw}{\\mathbf{w}}$\n",
      "$\\newcommand{\\bt}{\\mathbf{t}}$\n",
      "$\\newcommand{\\by}{\\mathbf{y}}$\n",
      "$\\newcommand{\\bm}{\\mathbf{m}}$\n",
      "$\\newcommand{\\bS}{\\mathbf{S}}$\n",
      "$\\newcommand{\\bI}{\\mathbf{I}}$\n",
      "$\\newcommand{\\bA}{\\mathbf{A}}$\n",
      "$\\newcommand{\\bQ}{\\mathbf{Q}}$\n",
      "$\\newcommand{\\bR}{\\mathbf{R}}$\n",
      "$\\newcommand{\\bX}{\\mathbf{X}}$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Lab 2\n",
      "\n",
      "In the computer labs we will work with the Python programming language within a Jupyter notebook. Each week a new notebook is made available that contains the exercises that are to be handed-in. \n",
      "\n",
      "* You are expected to work in pairs.\n",
      "* Only one of each pair has to submit on blackboard. Make sure that you add the student ID of your partner in the submission comments.\n",
      "* The main notebook file you submit should read \"Lab[number]_[last name 1]_[last name 2].ipynb\", for example \"Lab2_Bongers_Versteeg.ipynb\". \n",
      "* Please make sure your code will run without problems!\n",
      "\n",
      "Feel free ask any questions during the computer lab sessions, or email the TA, Elise (e.e.vanderpol@uva.nl).\n",
      "\n",
      "**The due date for the labs is Friday, Sep 22 at 15:00**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%pylab inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Populating the interactive namespace from numpy and matplotlib\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## 1 Simple linear regression\n",
      "In this exercise, you will generate noisy data for a simple linear system $y = \\beta_0 + \\beta_1 x$ where we have one target and one predictor variable, and compute the solution of least-squares estimator using linear algebra."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 1.1 Generate data\n",
      "**[10 points]** Sample 20 datapoints $({x_i, y_i})$ for the following model: \n",
      "$$x \\in \\mathcal{N}(0, 3)$$\n",
      "$$y = \\beta_0 + \\beta_1 x + \\epsilon \\mathrm{,}$$\n",
      "where $\\epsilon \\in \\mathcal{N}(0,1)$ is standard normal and the parameters $\\beta_0$ and $\\beta_1$ are both taken randomly __once__ in the interval $(0,1)$ (and are thus kept fixed during sampling!). Make a scatterplot of your data."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 1.2  LS solution\n",
      "**[15 points]** What is the solution of the least-squares estimate for the parameters $\\hat{\\bb} = (\\hat{\\beta}_0, \\hat{\\beta}_1)$ for model $y = \\beta_0 + \\beta_1 x$ in terms of the dependent variable $y$ and the design matrix $\\mathbf{X}$? Write the solutions to these normal equations down in closed form in the markdown cell below. What are the dimensions of $\\hat{\\bb}$, $\\bX$ and $\\by$? \n",
      "\n",
      "Hint: see Bishop chapter 3, it helps to write the model in vectorized form!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "_[your answer here]_"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 1.3 Compute estimates\n",
      "**[10 points]** Create the design matrix $\\bX$ and compute the point estimation for the parameters $\\hat{\\bb}$ using the simulated data from 1.1."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 1.4 Plotting\n",
      "**[5 points]** Plot the model with the estimated parameters and the true parameters in the same scatterplot as the original data. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## 2 Multiple linear regression\n",
      "Here we go from simple to multiple linear regression, and encounter some difficulties that may arise."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 2.1 Repeating for multiple regression\n",
      "**[30]** Sample now 20 datapoints from a more complex model with multiple prediction variables:\n",
      "$$x_1 \\in \\mathcal{N}(0, 3)$$\n",
      "$$x_2 \\in \\mathcal{N}(0, 2)$$\n",
      "$$x_3 \\in \\mathcal{N}(0, 3)$$\n",
      "$$y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\beta_3 x_3 + \\epsilon \\mathrm{,}$$\n",
      "where $\\epsilon$ is again standard normal and the $\\beta_i$ are all randomly set in $(0,1)$. Repeat the above assignment by computing $\\bX$ and the least squares estimate of the parameters $\\hat{\\bb}$. Print the results for  $\\hat{\\bb}$ and the original parameters $\\bb$ together as a check.\n",
      "\n",
      "Hint: if you vectorized the computation in 1.3 correctly, you could re-use some code."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We have loaded some multivariate data, comprising of one target $y$ and 3 predictor variables $x_i$ as an example. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## example data.\n",
      "with open('data.npz', 'r') as f:\n",
      "    x_example = np.load(f)['x']\n",
      "    y_example = np.load(f)['y']\n",
      "    designmatrix_example = np.load(f)['designmatrix']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 2.2 Example data\n",
      "**[5 points]** Use the designmatrix $\\bX$ and target variable $\\by$ from the data loaded above in your implementation from problem 2 to get a least-square estimate for $\\bb$ assuming a linear regression model. What happens, and why?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "_[your answer here]_"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can factor any complex (and thus real-valued) $m \\times n$ matrix $\\bA$ in terms of an $m \\times n$ orthogonal matrix $\\bQ$ and an $n \\times n$ upper triangular matrix $\\bR$, a so-called QR decomposition.  \n",
      "### 2.3 QR decomposition\n",
      "**[10 points]** Rewrite the solution to the normal equations from 1.2 in terms of the QR decomposition of the designmatrix. Why could this form be more preferred?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "collapsed": true
     },
     "source": [
      "_[your answer here]_"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 2.4 Implementation\n",
      "There are many different methods to calculate the QR decomposition to find here we will use a modified Gram-Schmidt orthogonalization algorithm as seen below."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def modified_gram_schmidt(mat):\n",
      "    m, n = mat.shape\n",
      "    \n",
      "    q = np.zeros((m,n))\n",
      "    r = np.zeros((n,n))\n",
      "\n",
      "    for k in range(n):\n",
      "        r[k, k]     = np.linalg.norm(mat[:, k])\n",
      "        q[:, k]     = mat[:,k]/r[k,k]\n",
      "        r[k, k+1:n] = np.dot(q[:,k], mat[:,k+1:n])\n",
      "        mat[:, k+1:n] = mat[:,k+1:n] - np.outer(q[:,k], r[k,k+1:n])\n",
      "    return q, r"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**[10 points]** Explain __roughly__ why this algorithm would return an orthogonalized $\\bQ$ (you are allowed to add comments to the code above). Apply it on the designmatrix of your example, show that the decomposition works and calculate an estimate $\\hat{\\bb}$."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## 2.5 Numpy\n",
      "**[5 points]**  Use the least-squares implementation in _numpy_ on the example data to get the parameters for $\\by = \\bX \\bb$  and compare with what you found in 2.2 and 2.4."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    }
   ],
   "metadata": {}
  }
 ]
}
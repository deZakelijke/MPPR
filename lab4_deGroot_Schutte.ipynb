{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mathematical Principles in Pattern Recognition (2016/2017)\n",
    "$\\newcommand{\\bPhi}{\\mathbf{\\Phi}}$\n",
    "$\\newcommand{\\bb}{\\mathbf{b}}$\n",
    "$\\newcommand{\\bx}{\\mathbf{x}}$\n",
    "$\\newcommand{\\bw}{\\mathbf{w}}$\n",
    "$\\newcommand{\\bt}{\\mathbf{t}}$\n",
    "$\\newcommand{\\by}{\\mathbf{y}}$\n",
    "$\\newcommand{\\bm}{\\mathbf{m}}$\n",
    "$\\newcommand{\\bS}{\\mathbf{S}}$\n",
    "$\\newcommand{\\bI}{\\mathbf{I}}$\n",
    "$\\newcommand{\\bA}{\\mathbf{A}}$\n",
    "$\\newcommand{\\bQ}{\\mathbf{Q}}$\n",
    "$\\newcommand{\\bR}{\\mathbf{R}}$\n",
    "$\\newcommand{\\bX}{\\mathbf{X}}$\n",
    "$\\newcommand{\\bsigma}{\\boldsymbol{\\sigma}}$\n",
    "$\\newcommand{\\bmu}{\\boldsymbol{\\mu}}$\n",
    "$\\newcommand{\\bpi}{\\boldsymbol{\\pi}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4\n",
    "\n",
    "In the computer labs we will work with the Python programming language within a Jupyter notebook. Each week a new notebook is made available that contains the exercises that are to be handed-in. \n",
    "\n",
    "* You are expected to work in pairs\n",
    "* Use Python 2.7!\n",
    "* Only one of each pair has to submit on blackboard. Make sure that you add the student ID of your partner in the submission comments.\n",
    "* The main notebook file you submit should read \"Lab[number]_[last name 1]_[last name 2].ipynb\", for example \"Lab2_Bongers_Versteeg.ipynb\". \n",
    "* Please make sure your code will run without problems!\n",
    "\n",
    "Feel free ask any questions during the computer lab sessions, or email the TA, Elise (e.e.vanderpol@uva.nl).\n",
    "\n",
    "**The due date for the labs is Friday, Oct 13 at 15:00**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Bayesian regression\n",
    "So far we have been using the frequentist approach to regression problems, where we find point-wise estimates of the parameters of a model. In this lab we make a detour to the Bayesian viewpoint with a Bayesian linear regression using polynomial basis functions. First we will generate some noisy data, and use an appropriate prior with polynomial basis functions to find the posterior and predictive distributions. \n",
    "\n",
    "Note: To stay in line with the notation in Bishop chapter 3.3, we will notate target variable of the regression as $t$ and the features as $x$ throughout this exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Generate data\n",
    "**[10 points]**Create a function `generate_data(n)` that returns $N$ samples from a noisy sinusoidal model: \n",
    "$$\n",
    "   t = y(x) + \\epsilon = \\sin(2\\pi \\ x) + \\epsilon \n",
    "$$\n",
    "with\n",
    "$$\n",
    "   x \\sim \\mathcal{U}(0,1) \\\\\n",
    "   \\epsilon \\sim \\mathcal{N}(0,0.2)\n",
    "$$\n",
    "where $\\mathcal{U}(a,b)$ denotes the uniform distribution between $a$ and $b$, and $\\mathcal{N}$ the usual Gaussian distribution. \n",
    "\n",
    "Make a scatterplot of features $x$ versus targets $t$ with $N = 20$ samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f37060e2128>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlAEgSYUyACSpUAaAJBXKAJCkQv0/273KoNeJ4qYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3706163ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def generate_data(n):\n",
    "    result = []\n",
    "    x_list = []\n",
    "    for i in range(n):\n",
    "        x = random_sample()\n",
    "        e = random.normal(0, 0.2)\n",
    "        new_sample = sin(2*pi*x) + e\n",
    "        result.append(new_sample)\n",
    "        x_list.append(x)\n",
    "    return result, x_list\n",
    "        \n",
    "\n",
    "n = 20\n",
    "data,x  = generate_data(n)\n",
    "plt.scatter(x, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The linear regression model we will use here is in terms of polynomial basisfunction, $\\phi_i = x^i$, such that we have \n",
    "$$\n",
    "    y(\\bx) = \\sum_{i=0}^{M-1} w_i \\phi_i\n",
    "$$\n",
    "where $w_i$ are the weight parameters and $M$ is the total number of model parameters. I.e. for $M = 3$ we have $3$ basisfunctions $\\phi_0 = 1$; $\\ \\phi_1(x) = x$; and $\\phi_2(x) = x^2$.\n",
    "### 1.2 Design matrix\n",
    "**[10 points]**\n",
    "Write a function `designmatrix_poly(x,m)` that for a given vector of data-samples $\\bx$ and $M$ returns the designmatrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def designmatrix_poly(x,m):\n",
    "    result_matrix = matrix(ones((size(x), m)))\n",
    "    for i in range(len(x)):\n",
    "        for j in range(1,m):\n",
    "            result_matrix[i,j] = x[i] ** j\n",
    "    return result_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Prior samples\n",
    "**[10 points]** First consider the prior distribution on the model parameters $\\bw$. Analogous to Bishop chapter 3.3.1, we will use an isotropic Gaussian with zero mean, \n",
    "$$\n",
    "p(\\bw) = \\mathcal{N}(\\bw \\mid \\mathbf{0}, \\alpha^{-1} \\bI)\n",
    "$$\n",
    "where the $\\alpha$ hyperparameter indicates its precision and $\\bw$ are the weights for basis-functions $\\phi_i(x) = x^i$. Draw a few samples from this prior distribution with fixed $\\alpha = 2$ for $M = 4$ and plot the resulting model in a few plots (in the same range as the simulated data will have)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([-0.20610746, -1.62208323,  0.76246788, -1.42925417]), array([ 0.32797169,  0.81350537,  1.5126038 , -0.11732051]), array([ 0.34480882,  0.23383479, -0.38053127,  0.35167894]), array([ 0.16366228,  0.21936665, -1.25522702,  0.19715494]), array([-0.37605244,  0.80767163, -0.21150004, -1.16440502]), array([ 0.66475806, -0.81461265, -1.07355783,  1.11062792]), array([-1.15909388, -0.44561955, -0.44866884, -1.40648592]), array([-0.54214747,  0.67419067,  0.81615743, -0.91520975]), array([-0.17279684, -0.43079546,  0.02291546, -0.17747163]), array([ 0.3295354 , -0.41370439,  0.68056325, -1.2139225 ])]\n"
     ]
    }
   ],
   "source": [
    "alpha = 2\n",
    "M = 4\n",
    "mu = [0,0,0,0]\n",
    "sigma = alpha ** -1 * identity(M)\n",
    "w = []\n",
    "nr_samples = 10\n",
    "\n",
    "for _ in range(nr_samples):\n",
    "    w.append(random.multivariate_normal(mu, sigma))\n",
    "\n",
    "print(w)\n",
    "\n",
    "# ik snap niet hoe ik het moet plotten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Posterior distribution\n",
    "**[35 points]** The corresponding posterior distribution is a Gaussian defined by parameters\n",
    "$$\n",
    "    \\bm_N = \\beta \\bS_N \\bPhi^T \\bt \\\\\n",
    "    \\bS_N^{-1} = \\alpha \\bI + \\beta \\bPhi^T \\bPhi\n",
    "$$\n",
    "where $\\bm_N$ and $\\bS_N$ are the mean and covariance of the posterior, $\\bPhi$ is the designmatrix and $\\beta$ is a noise precision parameter that we shall consider to be a given constant, set to $\\beta = (1\\ /\\ 0.2)^{2}$.\n",
    "\n",
    "Write a function `compute_posterior` that returns the $\\bm_N$ and $\\bS_N$ for given input $\\alpha$, $\\beta$, $M$, $\\bx$, $\\bt$ that uses `designmatrix_poly` from above. \n",
    "\n",
    "Generate four datasets with $N = \\{1, 2, 4, 25\\}$ \n",
    "and use each of those to plot 5 samples of the posterior, as you did earlier with the prior. (Hint: compare to Bishop figure 3.9) What is the overall trend?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_posterior(n):\n",
    "    t, x = generate_data(n)\n",
    "    Phi = designmatrix_poly(x,M)\n",
    "    S_1 = alpha*identity(M) + beta*Phi.T*Phi\n",
    "    m_1 = beta*inv(S_1)*Phi.T*matrix(t).T\n",
    "    return S_1, m_1\n",
    "\n",
    "    \n",
    "N = [1, 2, 4, 25]\n",
    "M = 4\n",
    "alpha = 2\n",
    "beta = (1/0.2) ** 2\n",
    "N = [1,2,4,25]\n",
    "m = []\n",
    "S = []\n",
    "\n",
    "for n in N:\n",
    "    S_1, m_1 = compute_posterior(n)\n",
    "    S.append(S_1)\n",
    "    m.append(m_1)\n",
    "    \n",
    "# fucking numpy bullshit\n",
    "# de volgende regel werkt niet dus ik heb het vervangen\n",
    "# random.multivariate_normal(m[-1], S[-1])\n",
    "sample =[random.multivariate_normal(array(m[-1].T)[0], S[-1]) for _ in range(5)]   \n",
    "# ik snap niet hoe ik het moet plotten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[answer here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Predictive distribution\n",
    "**[35 points]** The predictive distribution of a new target $t$ for new input feature $x$ is in this case given by the following equations (Bishop 3.58 and 3.59):\n",
    "$$\n",
    "p(t \\mid \\bx, \\bt, \\alpha, \\beta) = \\mathcal{N}(t \\mid \\bm_N^T \\phi(\\bx), \\sigma_N^2(\\bx)) \\\\\n",
    "\\sigma_N^2(x) = \\frac{1}{\\beta} + \\phi(\\bx)^T \\bS_N \\phi(\\bx)\n",
    "$$\n",
    "\n",
    "Create a function `compute_predictive` that returns the parameters of the predictive distribution. Make use of your `compute_posterior` implementation!\n",
    "\n",
    "Using the four datasets from 1.5, plot the four resulting Gaussian predictive distributions $p(t \\mid x)$ for one particular random new $x$ in the same figure. How does it change with increasing $N$? Compare it with your figure from 1.4 or figure 3.8 in Bishop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_predictive():\n",
    "    \n",
    "    #?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[answer here]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
